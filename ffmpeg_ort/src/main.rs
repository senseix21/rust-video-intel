extern crate ffmpeg_next as ffmpeg;

use clap::Parser;
use ffmpeg::format::{input, Pixel};
use ffmpeg::media::Type;
use ffmpeg::software::scaling::{context::Context, flag::Flags};
use ffmpeg::util::frame::video::Video;
use ort::execution_providers::{CPUExecutionProvider, CUDAExecutionProvider};
use ort::session::builder::{GraphOptimizationLevel, SessionBuilder};
use std::fs::File;
use std::io::prelude::*;
use std::path::PathBuf;
use tracing_subscriber::prelude::*;

#[derive(Debug, Parser)]
pub struct Args {
    /// Path to input image (.jpeg/.png) or video file (.mp4/.mkv).
    input: PathBuf,
    /// Whether to attempt to use `cuda` hw acceleration.
    /// This may silently fail and fallback to cpu acceleration presently.
    #[arg(long, action, default_value = "false")]
    cuda: bool,
    /// Yolov8 onnx model file to use.
    #[arg(long, short, default_value = "_models/yolov8s.onnx")]
    model: String,
}

fn main() -> anyhow::Result<()> {
    // Initialize logging.
    tracing_subscriber::registry()
        .with(
            tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| "warn,gstreamed_ort=info".into()),
        )
        .with(tracing_subscriber::fmt::layer())
        .init();

    let args = Args::parse();

    // Load model into ort.
    let (_ep, ep_name) = if args.cuda {
        (CUDAExecutionProvider::default().build(), "cuda")
    } else {
        (CPUExecutionProvider::default().build(), "cpu")
    };

    let session = SessionBuilder::new()?
        .with_optimization_level(GraphOptimizationLevel::Level3)?
        // .with_intra_threads(1)?
        .commit_from_file(&args.model)?;
    log::debug!("{session:?}");

    log::info!(
        "Prepared ort {ep_name} session with model: {:?}",
        args.model
    );

    // Initialize ffmpeg and open video.
    ffmpeg::init().unwrap();

    if let Ok(mut ictx) = input(&args.input) {
        let input = ictx
            .streams()
            .best(Type::Video)
            .ok_or(ffmpeg::Error::StreamNotFound)?;
        let video_stream_index = input.index();

        let context_decoder = ffmpeg::codec::context::Context::from_parameters(input.parameters())?;
        let mut decoder = context_decoder.decoder().video()?;

        let mut scaler = Context::get(
            decoder.format(),
            decoder.width(),
            decoder.height(),
            Pixel::RGB24,
            decoder.width(),
            decoder.height(),
            Flags::BILINEAR,
        )?;

        let mut frame_index = 0;

        let mut receive_and_process_decoded_frames =
            |decoder: &mut ffmpeg::decoder::Video| -> Result<(), ffmpeg::Error> {
                let mut decoded = Video::empty();
                while decoder.receive_frame(&mut decoded).is_ok() {
                    let mut rgb_frame = Video::empty();
                    scaler.run(&decoded, &mut rgb_frame)?;
                    save_file(&rgb_frame, frame_index).unwrap();
                    frame_index += 1;
                }
                Ok(())
            };

        for (stream, packet) in ictx.packets() {
            if stream.index() == video_stream_index {
                decoder.send_packet(&packet)?;
                receive_and_process_decoded_frames(&mut decoder)?;
            }
        }
        decoder.send_eof()?;
        receive_and_process_decoded_frames(&mut decoder)?;
    }

    Ok(())
}

fn save_file(frame: &Video, index: usize) -> std::result::Result<(), std::io::Error> {
    let mut file = File::create(format!("frame{}.ppm", index))?;
    file.write_all(format!("P6\n{} {}\n255\n", frame.width(), frame.height()).as_bytes())?;
    file.write_all(frame.data(0))?;
    Ok(())
}
